{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Classification of Podium Finishing at HKJC using Multinomial Naive Bayes\"\n",
    "---\n",
    "In this section, we will be generating a Multinomial Naive Bayes Model that attempts to predict whether a horse finishes on the podium (1st place, 2nd place, or 3rd place) in any given race. Predicting podium finishes makes up a giant portion of any horse racing betting market and the HKJC betting market is no exception. For this analysis, conducted using Python, we are going to be looking at how we can we use some categorical/discrete numerical variables in our dataset as determinants of podium finishing. As discussed in the Naive Bayes Intro section, Naive Bayes has a Multinomial Classifier algorithim that is suited for handling a feature set that is all discrete, numerical variables. We are going to be \"dummy coding\" our categorical variables as discrete, numerical variables in order to apply the Multinomial NB algorithim (see this Stack Exchange [link](https://stats.stackexchange.com/questions/93928/naive-bayes-continuous-and-categorical-predictors]) for more information on why we are able to dummy code our categorical variables and still use Multinomial NB). It is through this analysis that we will be able to see if a horse's attributes like sex, color, and import type and also naturally discrete variables like draw, rating, and days of rest are able to succesfully classify podium finishers.\n",
    "\n",
    "This section will be completed using Python.\n",
    "\n",
    "# Data Preparation\n",
    "We will begin this analysis by prepping and formatting our data, so that it may be properly read by our algorithim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_153880/915142976.py:3: DtypeWarning: Columns (10,18,25,26,27,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  perf = pd.read_csv('../../../data/01-modified-data/perf.clean.no.error.csv')\n"
     ]
    }
   ],
   "source": [
    "# Reading in our data\n",
    "horses = pd.read_csv('../../../data/01-modified-data/horses.clean.csv')\n",
    "perf = pd.read_csv('../../../data/01-modified-data/perf.clean.no.error.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to join horse attributes from the horses data set with the performance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to join color, sex, and import type with perf data.\n",
    "perf_clean = pd.merge(perf,horses[[\"horse_id\",\"colour\",\"sex\",\"import_type\"]],on=\"horse_id\",how = \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create a variable \"podium\" that is equal to 1 if a horse placed in the top 3 and 0 if it did not. This variable is what we will be trying to classify with a Categorical Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_clean['podium'] = np.nan\n",
    "perf_clean['podium'] = np.where(perf_clean['final_placing'].isin([1, 2, 3]), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a subset of data with our features of interest. Our features of interest are all of our categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_cat_classifier = perf_clean[['podium','colour','sex','import_type','draw','rating','days_between']]\n",
    "perf_cat_classifier = perf_cat_classifier.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our feature set, we must now dummy code our categorical features into numbers in order for our Naive Bayes algorithim to be able to handle the features. We will be using sklearn's preproccesing package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "perf_classifier_encode = perf_cat_classifier\n",
    "\n",
    "perf_classifier_encode = perf_classifier_encode.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "perf_classifier_encode = pd.DataFrame(perf_classifier_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podium</th>\n",
       "      <th>colour</th>\n",
       "      <th>sex</th>\n",
       "      <th>import_type</th>\n",
       "      <th>draw</th>\n",
       "      <th>rating</th>\n",
       "      <th>days_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   podium  colour  sex  import_type  draw  rating  days_between\n",
       "0       0       0    3            1     5      72            22\n",
       "1       0       0    3            1     0      71            24\n",
       "2       0       0    3            1     0      67           246\n",
       "3       0       0    3            1     8      66            67\n",
       "4       0       0    3            1    13      64           135\n",
       "5       0       0    3            1     6      62            11\n",
       "6       0       0    3            1    13      60            20\n",
       "7       1       0    3            1     3      58            11\n",
       "8       1       2    3            1     6      76            13\n",
       "9       1       2    3            1     3      77            23"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_classifier_encode.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to perform a feature selection process, so that we are using an optimal feature set for our NB classifier. We do not want to be including features in our classifier that detract from the effectivness of said classifier. We will now go ahead and define our feature set, which is all categorical and discrete numerical variables, and dependent variable, y (podium)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(perf_classifier_encode.loc[:, perf_classifier_encode.columns != 'podium'])\n",
    "y = np.array([perf_classifier_encode['podium']])\n",
    "y = y.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now go ahead and create a training, validation, and test set out of our data. The first 10 random indicies for our training, validation, and test splits are printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[184317, 35142, 156934, 211440, 254189, 120768, 50992, 187576, 149295, 114769]\n",
      "[49235, 119729, 212655, 217398, 47295, 42808, 179741, 243627, 1139, 231747]\n",
      "[136214, 43047, 18090, 61177, 180581, 210039, 92160, 17150, 81449, 181451]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(100)\n",
    "N=x.shape[0]\n",
    "l = [*range(N)]     # indices\n",
    "cut = int(0.8 * N) #80% of the list\n",
    "cut2 = int((N - cut)/2 + cut)\n",
    "random.shuffle(l)   # randomize\n",
    "train_index = l[:cut] # first 80% of shuffled list\n",
    "validate_index = l[cut:cut2] # 10% of shuffled list\n",
    "test_index = l[cut2:] # 10% of shuffled list\n",
    "\n",
    "print(train_index[0:10])\n",
    "print(validate_index[0:10])\n",
    "print(test_index[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now go ahead and fit our model and find the precision of the model on both the training and test sets, along with the time it takes to evaluate the models. This fitting process should be fairly computationally inexpensive because our feature set is small, but it is still a good idea to check computing time with any model fitting. Precision is our metric of interest over any of the other evaluation metrics.\n",
    "\n",
    "The reasoning for wanting to maximize precision over any of the other models is that precision tells us out of all the horse podium finishers we are predicting, we are predicting X percentage correct. In the betting world, being right is what makes you money. Measures like accuracy and negative predictive value, which help tell us how well our model is predicting horses that do NOT finish on the podium, are not helpful to us in a betting scenario. With a measure like sensitivity (recall), we are quantifying out of all the possible podium finishers, we are succesfully predicting X percentage of the total podium finisher pool. This measure is not totally unhelpful as it tells us the extent to which we are maximizing potential betting opportunities, but for the sake of this analysis, we care more about being right than maximizing potential betting opportunities, hence precision was our measure of interest for evaluating all of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(256936, 6) (256936, 1)\n",
      "(256936, 6) (256936, 1)\n",
      "27.903000561218498 27.27272727272727 0.051897600000017974 0.13326610000001438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score\n",
    "import time\n",
    "\n",
    "# Defining a function that generates a NB model\n",
    "def train_MNB_model(X,Y,i_print=False):\n",
    "\n",
    "    if(i_print):\n",
    "        print(X.shape,Y.shape)\n",
    "\n",
    "    #SPLIT\n",
    "    x_train=X[train_index]\n",
    "    y_train=Y[train_index].flatten()\n",
    "\n",
    "    x_test=X[test_index]\n",
    "    y_test=Y[test_index].flatten()\n",
    "\n",
    "    # INITIALIZE MODEL \n",
    "    model = MultinomialNB()\n",
    "\n",
    "    # TRAIN MODEL \n",
    "    start = time.process_time()\n",
    "    model.fit(x_train,y_train)\n",
    "    time_train=time.process_time() - start\n",
    "\n",
    "    # LABEL PREDICTIONS FOR TRAINING AND TEST SET \n",
    "    start = time.process_time()\n",
    "    yp_train = model.predict(x_train)\n",
    "    yp_test = model.predict(x_test)\n",
    "    time_eval=time.process_time() - start\n",
    "\n",
    "    prec_train= precision_score(y_train, yp_train)*100\n",
    "    prec_test= precision_score(y_test, yp_test)*100\n",
    "\n",
    "    if(i_print):\n",
    "        print(prec_train,prec_test,time_train,time_eval)\n",
    "\n",
    "    return (prec_train,prec_test,time_train,time_eval)\n",
    "\n",
    "\n",
    "#TEST\n",
    "print(type(x),type(y))\n",
    "print(x.shape,y.shape)\n",
    "(acc_train,acc_test,time_train,time_eval)=train_MNB_model(x,y,i_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our initial model, we see a test precision of around 27%. Also, as expected, computational time is very low for both. Now, we will go ahead and analyze how each of the features impact our classifier, allowing us to determine if we should remove any features.\n",
    "\n",
    "We will now peform an analysis to identify a best subset of features that gives us the best test precision. We will use the itertools package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcarswell/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  1  5 72]\n",
      " [ 3  1  0 71]\n",
      " [ 3  1  0 67]\n",
      " ...\n",
      " [ 3  3  1 58]\n",
      " [ 3  3  4 55]\n",
      " [ 3  3  6 60]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "best_prec = 0\n",
    "m = x.shape[1]\n",
    "\n",
    "for i in range(1, m + 1):\n",
    "          subset = itertools.combinations(range(m),i)\n",
    "\n",
    "          for j in subset:\n",
    "               x_subset = x[:,j]\n",
    "               (prec_train,prec_test,time_train,time_eval)=train_MNB_model(x_subset,y,i_print=False)\n",
    "\n",
    "               if prec_test > best_prec:\n",
    "                    best_prec = prec_test\n",
    "                    best_subset = x_subset\n",
    "\n",
    "print(best_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output optimal set of features that maximizes precision is going to be Import Type, Draw, and Rating. We will now only be proceeding with these features.\n",
    "\n",
    "# Fitting a Final, \"Optimal\" NB Model\n",
    "We will now use our subset of features to fit a final NB model. Our training model, consisting of the optimal feature set, will take a split of test data from the original dataset in order to give the model \"unseen\" data with classfication labels we already know, so that we can develop accurate metrics surrounding the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(perf_classifier_encode[['import_type','draw','rating']])\n",
    "y = np.array([perf_classifier_encode['podium']])\n",
    "y = y.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "N=x.shape[0]\n",
    "l = [*range(N)]     # indices\n",
    "cut = int(0.8 * N) #80% of the list\n",
    "cut2 = int((N - cut)/2 + cut)\n",
    "random.shuffle(l)   # randomize\n",
    "train_index = l[:cut] # first 80% of shuffled list\n",
    "validate_index = l[cut:cut2] # 10% of shuffled list\n",
    "test_index = l[cut2:] # 10% of shuffled list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256936, 3) (256936, 1)\n",
      "33.54893138357705 35.189873417721515 0.04381219999999075 0.20717200000001412\n"
     ]
    }
   ],
   "source": [
    "(acc_train,acc_test,time_train,time_eval)=train_MNB_model(x,y,i_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that our model has a train precision of 33.5% test precision around 35% which is fairly decent. Because both our training and test precisions are very close in magnitude, with the test precision being slightly larger, we can conclude that our model is definitely not overfit as the test precision would be much lower if this were the case. There might be the argument that our model underfits the data because our test precision is so close to the train precision, and as you will see later, our F-1 score is pretty abysmal. We explore this idea in a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "x_train=x[train_index]\n",
    "y_train=y[train_index].flatten()\n",
    "\n",
    "x_test=x[test_index]\n",
    "y_test=y[test_index].flatten()\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "yp_test = clf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, yp_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.66311201058613\n",
      "Precision: 35.189873417721515\n",
      "Sensitivity: 2.0902255639097747\n",
      "Specificity: 98.65574459147238\n",
      "F1 Score: 3.946061036195883\n"
     ]
    }
   ],
   "source": [
    "Accuracy = metrics.accuracy_score(y_test, yp_test)\n",
    "Precision = metrics.precision_score(y_test, yp_test)\n",
    "Sensitivity = metrics.recall_score(y_test, yp_test)\n",
    "Specificity = metrics.recall_score(y_test, yp_test,pos_label=0)\n",
    "F1_score = metrics.f1_score(y_test, yp_test)\n",
    "print(\"Accuracy:\",Accuracy*100)\n",
    "print(\"Precision:\", Precision*100)\n",
    "print(\"Sensitivity:\",Sensitivity*100)\n",
    "print(\"Specificity:\",Specificity*100)\n",
    "print(\"F1 Score:\",F1_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can notice a few things. First of all, our model is about 73% accurate which is very strong. At the surface level, our precision is also fairly strong at around 35%. Of the horse podium finishers predicted, our model predicts correctly predicts them as podium finishers 35% of the time. HOWEVER, our confusion matrix shows that our model only predicted 139 out of the over 20,0000 observations as correctly positive podium finishers. We can see in the confusion matrix that the model is REALLY good at predicting non-podium finishers with a specificity of around 99%. This characteristic is not really impressive in practicality, however, as we are really just interested in predicting horse podium finishers. Resultantly, our ability in predicting positive results is very low, with an EXTREMELY low sensitity score. Our F-1 score is also VERY low, showing that this model is overall not very effective at all for predicting horse racing podium finishes. This characteristic is also an indication that our model is very underfitted as we are not capturing all neccessary patterns and behaviors neccessary for correctly prediciting podium finishes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Overall, our model is not a fantastic overall tool for predicting horse podium finishers. What is a valuable takeaway from this exercise, however, is we can very strongly observe what characteristics drive a horse to NOT finsh on the podium. A horse's attributes like color and sex (which delineate what type of horse we are observing) really do not have any impact on the probability a horse has a podium finish. A horse's import type can, however, be used to help inform if a horse will likely not finish on the podium. Rating and draw are the most important features here. Our model is able to show us that given a horse's draw and rating, we can discount its likelihood to finish on the podium if its draw and rating are below a certain threshold. While this threshold is not clearly defined yet, this phenomena does allow us to understand that draw and rating will be important features as we continue to try and predict horse performance with more advanced statistical methods. These findings will be reported in the final conclusive report generated for this project, along with being used as the basis for much of the feature selection we use as we go forth developing more advanced models in this project, especially as we try to increase precision scores under the decision tree section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
